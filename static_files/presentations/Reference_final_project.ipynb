{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nimport numpy as np\nimport json\nimport sys\nimport os\n\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n\ndirectory = \"/kaggle/working/\"\nuser_data = directory + \"data/\"\nvalid_data = directory + \"data/\"\ntest_data = directory + \"label_book/\" # this can be the label book, or any other test set you create","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-02T02:21:06.636407Z","iopub.execute_input":"2022-05-02T02:21:06.637252Z","iopub.status.idle":"2022-05-02T02:21:06.644109Z","shell.execute_reply.started":"2022-05-02T02:21:06.637210Z","shell.execute_reply":"2022-05-02T02:21:06.643043Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# Rules\n\n- Submission must have less than 10,000 images combined in training and validation\n\n**Submissions will be evaluated according to two categories:**\n1. **Best Performance Overall**\n2. **Most Innovative**","metadata":{}},{"cell_type":"markdown","source":"# Getting started\n\n\nFirst, download the dataset by clicking into the bundle (https://worksheets.codalab.org/bundles/0xcea1d733e1f144d9aba83929af51f191) and press the download button. The dataset contains ~3000 images of handwritten roman numerals 1-10. **Your task is to optimize model performance by improving the dataset and making training and validation splits.**\n\nYour submission should be a zip file with the following file structure, and with your training and validation data split into different folders. You can rename `sample_submission` whatever you like, but *the name of your zip file should match your folder name*. In this example, it should be called `sample_submission.zip`. When the zip file is expanded, the file structure and names inside must match the following:\n\n    sample_submission/\n        train/\n            i/\n            ii/\n            iii/\n            iv/\n            ...\n        val/\n            i/\n            ii/\n            iii/\n            iv/\n            ...\n\n\nYou can try fixing incorrect labels, adding data for side case tuning, apply data augmentation techniques, or use any other method to improve the data. You may also find it helpful to take a look at the training script to get a better sense of the preprocessing and model (these are held fixed). The script will resize all images to `(32, 32)` and run them through a cut off ResNet50. \n[dataset train.py](https://worksheets.codalab.org/bundles/0x57030e4a2d034af4b8efa38df4ff6af6)\n\nIf you choose to create your own data, you may find this script helpful for converting your images:\n[dataset convert.py](https://worksheets.codalab.org/bundles/0x3a2514052d9240ffa24774a7092b82b8)\n\nWe also provide you with a label book that has five examples for each label. You can use it as a sample test set as you create your submission: \n[dataset label_book](https://worksheets.codalab.org/bundles/0xe1d24af2ca5e4d95be653f1c7877125e)","metadata":{}},{"cell_type":"code","source":"!pip install --upgrade --no-cache-dir gdown","metadata":{"execution":{"iopub.status.busy":"2022-05-02T02:17:11.280598Z","iopub.execute_input":"2022-05-02T02:17:11.280882Z","iopub.status.idle":"2022-05-02T02:17:45.039551Z","shell.execute_reply.started":"2022-05-02T02:17:11.280852Z","shell.execute_reply":"2022-05-02T02:17:45.038528Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# https://drive.google.com/file/d/1z-kOIm8EWuxGW-hD_i6DrjYU2C3kzlst/view?usp=sharing\n!gdown --id 1z-kOIm8EWuxGW-hD_i6DrjYU2C3kzlst","metadata":{"execution":{"iopub.status.busy":"2022-05-02T02:17:45.042767Z","iopub.execute_input":"2022-05-02T02:17:45.043099Z","iopub.status.idle":"2022-05-02T02:18:00.737936Z","shell.execute_reply.started":"2022-05-02T02:17:45.043056Z","shell.execute_reply":"2022-05-02T02:18:00.737052Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# https://drive.google.com/file/d/1DUD1Lh7f5RcTHihkylNuhy4ozRGtoA_z/view?usp=sharing\n!gdown --id 1DUD1Lh7f5RcTHihkylNuhy4ozRGtoA_z","metadata":{"execution":{"iopub.status.busy":"2022-05-02T02:18:00.741711Z","iopub.execute_input":"2022-05-02T02:18:00.741966Z","iopub.status.idle":"2022-05-02T02:18:06.075029Z","shell.execute_reply.started":"2022-05-02T02:18:00.741936Z","shell.execute_reply":"2022-05-02T02:18:06.074202Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"!tar zxf data.tar.gz\n!tar zxf test.gz","metadata":{"execution":{"iopub.status.busy":"2022-05-02T02:18:06.079140Z","iopub.execute_input":"2022-05-02T02:18:06.079374Z","iopub.status.idle":"2022-05-02T02:18:07.679618Z","shell.execute_reply.started":"2022-05-02T02:18:06.079347Z","shell.execute_reply":"2022-05-02T02:18:07.678574Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"!ls label_book","metadata":{"execution":{"iopub.status.busy":"2022-05-02T02:18:07.681418Z","iopub.execute_input":"2022-05-02T02:18:07.681735Z","iopub.status.idle":"2022-05-02T02:18:08.414167Z","shell.execute_reply.started":"2022-05-02T02:18:07.681690Z","shell.execute_reply":"2022-05-02T02:18:08.413048Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"### DO NOT MODIFY BELOW THIS LINE, THIS IS THE FIXED MODEL ###\nbatch_size = 8\ntf.random.set_seed(123)\n\ntrain = tf.keras.preprocessing.image_dataset_from_directory(\n        user_data + '/train',\n        labels=\"inferred\",\n        label_mode=\"categorical\",\n        class_names=[\"i\", \"ii\", \"iii\", \"iv\", \"v\", \"vi\", \"vii\", \"viii\", \"ix\", \"x\"],\n        shuffle=True,\n        seed=123,\n        batch_size=batch_size,\n        image_size=(32, 32),\n    )\n\nvalid = tf.keras.preprocessing.image_dataset_from_directory(\n        user_data + '/val',\n        labels=\"inferred\",\n        label_mode=\"categorical\",\n        class_names=[\"i\", \"ii\", \"iii\", \"iv\", \"v\", \"vi\", \"vii\", \"viii\", \"ix\", \"x\"],\n        shuffle=True,\n        seed=123,\n        batch_size=batch_size,\n        image_size=(32, 32),\n)\n\ntotal_length = ((train.cardinality() + valid.cardinality()) * batch_size).numpy()\n\n#if total_length > 10_000:\n#    print(f\"Dataset size larger than 10,000. Got {total_length} examples\")\n#    sys.exit()\n\ntest = tf.keras.preprocessing.image_dataset_from_directory(\n        test_data,\n        labels=\"inferred\",\n        label_mode=\"categorical\",\n        class_names=[\"i\", \"ii\", \"iii\", \"iv\", \"v\", \"vi\", \"vii\", \"viii\", \"ix\", \"x\"],\n        shuffle=False,\n        seed=123,\n        batch_size=batch_size,\n        image_size=(32, 32),\n)\n\nbase_model = tf.keras.applications.ResNet50(\n        input_shape=(32, 32, 3),\n        include_top=False,\n        weights=None,\n)\nbase_model = tf.keras.Model(\n        base_model.inputs, outputs=[base_model.get_layer(\"conv2_block3_out\").output]\n)\n\ninputs = tf.keras.Input(shape=(32, 32, 3))\nx = tf.keras.applications.resnet.preprocess_input(inputs)\nx = base_model(x)\nx = tf.keras.layers.GlobalAveragePooling2D()(x)\nx = tf.keras.layers.Dense(10)(x)\nmodel = tf.keras.Model(inputs, x)\n\nmodel.compile(\n        optimizer=tf.keras.optimizers.Adam(lr=0.0001),\n        loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n        metrics=[\"accuracy\"],\n)\nmodel.summary()\n    \nloss_0, acc_0 = model.evaluate(valid)\nprint(f\"loss {loss_0}, acc {acc_0}\")\n\ncheckpoint = tf.keras.callbacks.ModelCheckpoint(\n        \"best_model\",\n        monitor=\"val_accuracy\",\n        mode=\"max\",\n        save_best_only=True,\n        save_weights_only=True,\n)\n\nhistory = model.fit(\n        train,\n        validation_data=valid,\n        epochs=100,\n        callbacks=[checkpoint],\n)\n\nmodel.load_weights(\"best_model\")\n\nloss, acc = model.evaluate(valid)\nprint(f\"final loss {loss}, final acc {acc}\")\n\ntest_loss, test_acc = model.evaluate(test)\nprint(f\"test loss {test_loss}, test acc {test_acc}\")","metadata":{"execution":{"iopub.status.busy":"2022-05-02T02:21:14.656817Z","iopub.execute_input":"2022-05-02T02:21:14.657441Z","iopub.status.idle":"2022-05-02T02:29:44.971012Z","shell.execute_reply.started":"2022-05-02T02:21:14.657392Z","shell.execute_reply":"2022-05-02T02:29:44.968045Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}